{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: quantize and run custom network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brief tutorial shows how to compress a custom network with EfficientBioAI and do the inference.\n",
    "- Model: naive 2d unet picked from:[github](https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py)\n",
    "- data: [Simulated nuclei of HL60 cells stained with Hoescht](http://celltrackingchallenge.net/2d-datasets/)\n",
    "- Compression strategy: L1 Norm Prune and PTQ int8 quantization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our package just focus on the compression part, and have no idea what is about the pre-processing of dataset and the logic of train/infer the data, users need to provide the following info for the compression:\n",
    "\n",
    "- a calibration dataloader containing several images;\n",
    "- the training api, which is used to do the fine-tuning of the compressed model; \n",
    "- the inference api, which is used to do the calibration during the quantization step.\n",
    "\n",
    "After providing these logics, users can use our package to compress the model and do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ISAS.DE/yu.zhou/miniconda3/envs/yz_deployment/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.unet import Unet\n",
    "from tqdm.contrib import tenumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have the pretrained model, so need to train it from scratch:\n",
    "!wget http://data.celltrackingchallenge.net/training-datasets/Fluo-N2DH-SIM+.zip -P ./data\n",
    "!unzip ./data/Fluo-N2DH-SIM+.zip -d ./data\n",
    "!rm ./data/Fluo-N2DH-SIM+.zip\n",
    "!python train_unet.py --data_path \"./data/Fluo-N2DH-SIM+/02\" --gt_path \"./data/Fluo-N2DH-SIM+/02_GT/SEG\" --num_epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility:\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "seed_value = 2023\n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "set_determinism(seed=seed_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compress the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"./unet.pth\")\n",
    "net = Unet(in_channels=1, classes=2)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Some logics required to be provided by users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-27 15:32:53,006 - Resource 'XMLSchema.xsd' is already loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ISAS.DE/yu.zhou/miniconda3/envs/yz_deployment/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "150it [00:00, 124091.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from monai.data import DataLoader, Dataset\n",
    "from custom import train, infer\n",
    "from data import generate_data_dict, train_transform, test_transform\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. train logic and infer logic:\n",
    "fine_tune = partial(train, num_epoch=2)\n",
    "calibrate = partial(infer, calib_num=4)\n",
    "\n",
    "# 2. Iterable data, here is a dataloader, used for calibration and fine-tuning:\n",
    "train_data_path = Path(\"./data/Fluo-N2DH-SIM+/02\")\n",
    "train_gt_path = Path(\"./data/Fluo-N2DH-SIM+/02_GT/SEG\")\n",
    "dataset = Dataset(\n",
    "    data=generate_data_dict(train_data_path, train_gt_path), transform=train_transform\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Compress the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] WARNING: onnxsim not found, if you want to use deploy_tengine, please install it.\n"
     ]
    }
   ],
   "source": [
    "from efficientbioai.compress_ppl import Pipeline\n",
    "from efficientbioai.utils import Dict2ObjParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = Path(\"./custom_config.yaml\")\n",
    "with open(cfg_path, \"r\") as stream:\n",
    "    config_yml = yaml.safe_load(stream)\n",
    "    config = Dict2ObjParser(config_yml).parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = Path(\"./exp\")\n",
    "Path.mkdir(exp_path, exist_ok=True)\n",
    "pipeline = Pipeline.setup(config_yml)\n",
    "pipeline(net, dataloader, fine_tune, calibrate, exp_path)\n",
    "pipeline.network2ir()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Infer the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the openvino inference engine to do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientbioai.infer.backend.openvino import create_opv_model\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config.model.model_name\n",
    "cfg_path = exp_path / f\"{model_name}.yaml\"\n",
    "infer_path = exp_path / \"academic_deploy_model.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, 77188.49it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_path = Path(\"./data/Fluo-N2DH-SIM+/01\")\n",
    "test_gt_path = Path(\"./data/Fluo-N2DH-SIM+/01_GT/SEG\")\n",
    "test_dataset = Dataset(\n",
    "    data=generate_data_dict(test_data_path, test_gt_path), transform=test_transform\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference with the quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = create_opv_model(infer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:16<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, batch_data in tenumerate(test_dataloader):\n",
    "    data, label = batch_data[\"img\"], batch_data[\"seg\"]\n",
    "    sliding_window_inference(\n",
    "        inputs=data,\n",
    "        predictor=quantized_model,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        roi_size=(128, 128),\n",
    "        sw_batch_size=1,\n",
    "        overlap=0.1,\n",
    "        mode=\"constant\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference with the normal model (float32, not on the engine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "normal_model = net\n",
    "normal_model.eval()\n",
    "for i, batch_data in tenumerate(test_dataloader):\n",
    "    data, label = batch_data[\"img\"], batch_data[\"seg\"]\n",
    "    sliding_window_inference(\n",
    "        inputs=data,\n",
    "        predictor=normal_model,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        roi_size=(128, 128),\n",
    "        sw_batch_size=1,\n",
    "        overlap=0.1,\n",
    "        mode=\"constant\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through compression, the inference speed is improved by 4x."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae4f827bcde0c94ad1c0f2596c29b2a24729759a5f96d744c12fba254054871a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
