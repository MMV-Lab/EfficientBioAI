{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: quantize and run custom network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brief tutorial shows how to compress a custom network with EfficientBioAI and do the inference. We use a simple 2d unet to do the 2d semantic segmentation task on the [Simulated nuclei of HL60 cells stained with Hoescht](http://celltrackingchallenge.net/2d-datasets/).  PTQ int8 quantization are tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.transforms import (\n",
    "    RandSpatialCropSamplesd,\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    Transform,\n",
    "    CastToTyped,\n",
    "    EnsureTyped,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    ")\n",
    "from monai.losses import DiceLoss\n",
    "from tqdm.contrib import tenumerate\n",
    "from aicsimageio import AICSImage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://data.celltrackingchallenge.net/training-datasets/Fluo-N2DH-SIM+.zip -P ./data\n",
    "!unzip ./data/Fluo-N2DH-SIM+.zip -d ./data\n",
    "!rm ./data/Fluo-N2DH-SIM+.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Generate the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./data/Fluo-N2DH-SIM+/02\"\n",
    "train_gt_path = \"./data/Fluo-N2DH-SIM+/02_GT/SEG\"\n",
    "\n",
    "test_data_path = \"./data/Fluo-N2DH-SIM+/01\"\n",
    "test_gt_path = \"./data/Fluo-N2DH-SIM+/01_GT/SEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_dict(data_path, gt_path):\n",
    "    data_dicts = []\n",
    "\n",
    "    for i, (data, label) in tenumerate(zip(os.listdir(data_path), os.listdir(gt_path))):\n",
    "        data_dict = {}\n",
    "        data_dict[\"img\"] = os.path.join(data_path, data)\n",
    "        data_dict[\"seg\"] = os.path.join(gt_path, label)\n",
    "        data_dict[\"fn\"] = data.split(\".\")[0]\n",
    "        data_dicts.append(data_dict)\n",
    "    return data_dicts\n",
    "\n",
    "\n",
    "class LoadTiffd(Transform):\n",
    "    def __init__(self, keys=[\"img\", \"seg\"]):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            x = AICSImage(data[key])\n",
    "            d[key] = x.get_image_data(\"YX\", S=0, T=0, C=0)\n",
    "        return d\n",
    "\n",
    "\n",
    "class Ins2Semd(Transform):\n",
    "    def __init__(self, keys=[\"seg\"]):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            d[key][d[key] != 0] = 1\n",
    "        return d\n",
    "\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        LoadTiffd(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "        CastToTyped(keys=[\"img\"], dtype=np.float32),\n",
    "        Ins2Semd(keys=[\"seg\"]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ScaleIntensityRangePercentilesd(\n",
    "            keys=[\"img\"], lower=0.5, upper=99.5, b_min=0, b_max=1\n",
    "        ),\n",
    "        RandSpatialCropSamplesd(\n",
    "            keys=[\"img\", \"seg\"], roi_size=(256, 256), num_samples=4, random_size=False\n",
    "        ),\n",
    "        ToTensord(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:00, 94494.68it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "    data=generate_data_dict(train_data_path, train_gt_path), transform=transform\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined a naive Unet model and train it with several epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.unet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:42<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1, avg loss: 0.4054159450531006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Unet(in_channels=1, classes=2)\n",
    "criterion = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epoch = 20\n",
    "net.to(device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "for i in range(num_epoch):\n",
    "    # train step:\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    for j, batch_data in tenumerate(dataloader):\n",
    "        data, label = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(data)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"epoch {i+1}/{num_epoch}, avg loss: {epoch_loss / len(dataloader)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./unet.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compress the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement PTQ int8 quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"./unet.pth\")\n",
    "net = Unet(in_channels=1, classes=2)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(model, data, calib_num, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, x in tenumerate(data):\n",
    "            y_hat = model(x[\"img\"].as_tensor())\n",
    "            if i >= calib_num:\n",
    "                break\n",
    "    return model\n",
    "\n",
    "\n",
    "def fine_tune(model, data, optimizer, criterion, num_epoch):\n",
    "    model.train()\n",
    "    for i in range(num_epoch):\n",
    "        epoch_loss = 0\n",
    "        for j, batch_data in tenumerate(data):\n",
    "            data, label = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"fine tune epoch {i+1}/{num_epoch}, avg loss: {epoch_loss / len(data)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientbioai.compress_ppl import Pipeline\n",
    "from efficientbioai.utils import Dict2ObjParser\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"./custom_config.yaml\"\n",
    "with open(cfg_path, \"r\") as stream:\n",
    "    config_yml = yaml.safe_load(stream)\n",
    "    config = Dict2ObjParser(config_yml).parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = \"./exp\"\n",
    "pipeline = Pipeline.setup(config_yml)\n",
    "pipeline(net, dataloader, fine_tune, calibrate, exp_path)\n",
    "pipeline.network2ir()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Infer the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the openvino inference engine to do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientbioai.infer.backend.openvino import create_opv_model\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config.model.model_name\n",
    "cfg_path = os.path.join(exp_path, f\"{model_name}.yaml\")\n",
    "infer_path = os.path.join(exp_path, \"academic_deploy_model.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, 115815.53it/s]\n"
     ]
    }
   ],
   "source": [
    "test_transform = Compose(\n",
    "    [\n",
    "        LoadTiffd(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "        CastToTyped(keys=[\"img\"], dtype=np.float32),\n",
    "        Ins2Semd(keys=[\"seg\"]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ScaleIntensityRangePercentilesd(\n",
    "            keys=[\"img\"], lower=0.5, upper=99.5, b_min=0, b_max=1\n",
    "        ),\n",
    "        ToTensord(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "test_dataset = Dataset(\n",
    "    data=generate_data_dict(test_data_path, test_gt_path), transform=test_transform\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference with the quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = create_opv_model(infer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:29<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, batch_data in tenumerate(test_dataloader):\n",
    "    data, label = batch_data[\"img\"], batch_data[\"seg\"]\n",
    "    sliding_window_inference(\n",
    "        inputs=data,\n",
    "        predictor=quantized_model,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        roi_size=(128, 128),\n",
    "        sw_batch_size=1,\n",
    "        overlap=0.1,\n",
    "        mode=\"constant\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference with the normal model (float32, not on the engine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:05<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "normal_model = net\n",
    "normal_model.eval()\n",
    "for i, batch_data in tenumerate(test_dataloader):\n",
    "    data, label = batch_data[\"img\"], batch_data[\"seg\"]\n",
    "    sliding_window_inference(\n",
    "        inputs=data,\n",
    "        predictor=normal_model,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        roi_size=(128, 128),\n",
    "        sw_batch_size=1,\n",
    "        overlap=0.1,\n",
    "        mode=\"constant\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae4f827bcde0c94ad1c0f2596c29b2a24729759a5f96d744c12fba254054871a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
