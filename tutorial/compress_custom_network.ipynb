{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress custom network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brief tutorial shows how to compress a custom network with EfficientBioAI. We use a simple 2d unet to do the 2d semantic segmentation task on the [Simulated nuclei of HL60 cells stained with Hoescht](http://celltrackingchallenge.net/2d-datasets/).  Both pruning and quantization are tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ISAS.DE/yu.zhou/miniconda3/envs/yz_deployment/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 16:11:34,612 - Resource 'XMLSchema.xsd' is already loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.transforms import RandSpatialCropSamplesd, Compose, AddChanneld, ScaleIntensityRanged, ToTensord, Transform, CastToTyped, EnsureTyped, ScaleIntensityRangePercentilesd\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "from monai.losses import DiceLoss\n",
    "from tqdm.contrib import tenumerate\n",
    "from aicsimageio import AICSImage\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/home/ISAS.DE/yu.zhou/Downloads/Fluo-N2DH-SIM+/02\"\n",
    "train_gt_path = \"/home/ISAS.DE/yu.zhou/Downloads/Fluo-N2DH-SIM+/02_GT/SEG\"\n",
    "\n",
    "test_data_path = \"/home/ISAS.DE/yu.zhou/Downloads/Fluo-N2DH-SIM+/03\"\n",
    "test_gt_path = \"/home/ISAS.DE/yu.zhou/Downloads/Fluo-N2DH-SIM+/03_GT/SEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ISAS.DE/yu.zhou/miniconda3/envs/yz_deployment/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "def generate_data_dict(data_path, gt_path):\n",
    "    data_dicts = []\n",
    "    \n",
    "    for i, (data,label) in tenumerate(zip(os.listdir(data_path), os.listdir(gt_path))):\n",
    "        data_dict = {}\n",
    "        data_dict['img'] = os.path.join(data_path, data)\n",
    "        data_dict['seg'] = os.path.join(gt_path, label)\n",
    "        data_dict['fn'] = data.split(\".\")[0]\n",
    "        data_dicts.append(data_dict)\n",
    "    return data_dicts\n",
    "\n",
    "class LoadTiffd(Transform):\n",
    "    def __init__(self, keys=['img','seg']) :\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            x = AICSImage(data[key])\n",
    "            d[key] = x.get_image_data(\"YX\", S=0, T=0, C=0)\n",
    "        return d\n",
    "\n",
    "class Ins2Semd(Transform):\n",
    "    def __init__(self, keys=['seg']) :\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            d[key][d[key]!=0] = 1\n",
    "        return d\n",
    "\n",
    "transform = Compose([\n",
    "                    LoadTiffd(keys=[\"img\", \"seg\"]), \\\n",
    "                    AddChanneld(keys=[\"img\", \"seg\"]), \\\n",
    "                    CastToTyped(keys=[\"img\"], dtype=np.float32), \\\n",
    "                    Ins2Semd(keys=[\"seg\"]), \\\n",
    "                    EnsureTyped(keys=[\"img\", \"seg\"]), \\\n",
    "                    ScaleIntensityRangePercentilesd(keys=[\"img\"], lower=0.5, upper=99.5, b_min = 0, b_max = 1), \\\n",
    "                    RandSpatialCropSamplesd(keys=[\"img\", \"seg\"], roi_size=(256, 256), num_samples=4, random_size=False), \\\n",
    "                    ToTensord(keys=[\"img\", \"seg\"])\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:00, 123507.18it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(data=generate_data_dict(train_data_path, train_gt_path), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "example  = next(iter(dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.unet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(in_channels=1, classes=2)\n",
    "criterion = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epoch = 100\n",
    "net.to(device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "for i in range(num_epoch):\n",
    "    # train step:\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    for j, batch_data in tenumerate(dataloader):\n",
    "        data, label = batch_data['img'].to(device), batch_data['seg'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(data)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'epoch {i+1}/{num_epoch}, avg loss: {epoch_loss / len(dataloader)}')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compress the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ISAS.DE/yu.zhou/EfficientBioAI/tutorial\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
